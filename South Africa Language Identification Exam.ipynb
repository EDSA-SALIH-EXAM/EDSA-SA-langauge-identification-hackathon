{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b59f49b-1a7a-4454-9623-d5eb37868a92",
   "metadata": {},
   "source": [
    "## South African language identification hackathon Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1aee0",
   "metadata": {},
   "source": [
    "## Makgothoma MP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Data Engineering</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Libraries For Data Preprocessing:\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "# Libraries For Feature Extraction, Model Building and Evaluation:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Library For Saving and Retrieving the Model File:\n",
    "import pickle\n",
    "\n",
    "# Library For handling warnings:\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setting global constants to ensure notebook results are reproducible\n",
    "PARAMETER_CONSTANT = 45 # random_state parameter for the train_test_split function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "In this section, I will load the language training dataset provided for the competition, as a *`pandas`* DataFrame.    \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading in the Data\n",
    "train_df =  pd.read_csv('train_set.csv')\n",
    "test_df = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71535c32-6206-484e-89c9-2e45c7068331",
   "metadata": {},
   "source": [
    "I will begin by displaying the first five rows of the Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aec75eac-4b2e-4c30-8f26-66b572c5e09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0beb83ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb750a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       index                                               text\n",
       "0         1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1         2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2         3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3         4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4         5                      Winste op buitelandse valuta.\n",
       "...     ...                                                ...\n",
       "5677   5678                   You mark your ballot in private.\n",
       "5678   5679  Ge o ka kgetha ka bowena go se šomiše Mofani k...\n",
       "5679   5680  E Ka kopo etsa kgetho ya hao ka hloko, hobane ...\n",
       "5680   5681  TB ke bokudi ba PMB, mme Morero o tla lefella ...\n",
       "5681   5682              Vakatjhela iwebhusayidi yethu ku-www.\n",
       "\n",
       "[5682 rows x 2 columns]>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33000 entries, 0 to 32999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  33000 non-null  object\n",
      " 1   text     33000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 515.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# look at Dataset information:\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f85bab5a-5bd0-4c4c-9767-462d2131f97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xho' 'eng' 'nso' 'ven' 'tsn' 'nbl' 'zul' 'ssw' 'tso' 'sot' 'afr']\n"
     ]
    }
   ],
   "source": [
    "print(train_df['lang_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86baa3e3-fd17-40c1-aed6-cd3cd49817b3",
   "metadata": {},
   "source": [
    "The above displayed is a list of the language codes representing each of the 11 official South African languages. These are also class labels.\n",
    "For the purpose of building an accurate classification model later in this project, it is important to ensure that the class labels are balanced.\n",
    "Class imbalance is a fairly common problem in classification tasks. If left unresolved, a trained model will be better at classifying the majority class than any other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f79e870-7a02-4890-b5fe-fb29ac433fd7",
   "metadata": {},
   "source": [
    "With this in mind, the next step is to Display the class distribution by creating a bar graph/plot. \n",
    "For this, I will use the `Matplotlib` and `Seaborn` Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c20304c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Class Distributions:\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(data=train_df, x=train_df['lang_id'].unique(), y=train_df['lang_id'].value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee455eb-556a-4bd4-bbf4-ad56f61ba579",
   "metadata": {},
   "source": [
    "The bar plot indicates that there is an even class distribution. 3000 records for each respective class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54087a38-c06b-4471-8fb1-3c151e50f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function to remove punctuation\n",
    "def remove_punctuation(message):\n",
    "    return ''.join([l for l in message if l not in string.punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a5cf08-68fc-4ccf-a534-0e27760a1809",
   "metadata": {},
   "source": [
    "A new column will be created to hold the cleaned data for the subsequent data cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ee7a045-ccd3-485e-a7a5-d28b5c4f44df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a New Column for clean data:\n",
    "train_df['clean_text'] = train_df['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e8050-90a0-47a4-b820-6b1aec79b31d",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee3b31a-5538-4248-bd7f-2f4e49db9baf",
   "metadata": {},
   "source": [
    "The process of tokenizing or splitting a string of text into a list of tokens is known as tokenization. Tokens can be thought of as pieces; for example, a word in a sentence is a token, and a sentence is a token in a paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d40068-ceea-461c-a019-5c6f663a3cec",
   "metadata": {},
   "source": [
    "In any NLP pipeline, tokenization is the first step. It has a major impact on the rest of the pipeline. Unstructured data and natural language text are broken down into chunks of information that can be regarded as separate elements using a tokenizer. The tokenizer to be used in this case is the `TreeBankWordTokenizer` from the `nltk` Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5d1f34bc-4318-4aad-905c-f7446e5af2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>[umgaqosiseko, wenza, amalungiselelo, kumaziko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>[idha, iya, kuba, nobulumko, bokubeka, umseben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>[the, province, of, kwazulunatal, department, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>[o, netefatša, gore, o, ba, file, dilo, ka, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>[khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  \\\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2     eng  the province of kwazulu-natal department of tr...   \n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [umgaqosiseko, wenza, amalungiselelo, kumaziko...  \n",
       "1  [idha, iya, kuba, nobulumko, bokubeka, umseben...  \n",
       "2  [the, province, of, kwazulunatal, department, ...  \n",
       "3  [o, netefatša, gore, o, ba, file, dilo, ka, mo...  \n",
       "4  [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting text into Tokens(word-lists):\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "train_df['clean_text'] = train_df['clean_text'].apply(tokenizer.tokenize)\n",
    "\n",
    "# Display the DataFrame after Tokenization:\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a18221-6c12-42b6-8c1c-23beb5eb86df",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stopword Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1b3af-22b5-4c66-bf74-15edfa5a4047",
   "metadata": {},
   "source": [
    "These are words that occur frequently in sentences, however, they do not contribute much to the information in a sentence. By stripping away these words, the low-level information is removed from the data, allowing the focus to remain on the important information. For this task, the `nltk` Library's Stopword Dictionary will be used for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "89f9f499-ca57-4139-8705-675e02b1203d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Function to Remove Stopwords:\n",
    "def chop_stopwords(tokens):    \n",
    "    return [t for t in tokens if t not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c8e2e23-b3ab-4514-8790-7216113398b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removing StopWords from the data:\n",
    "train_df['clean_text'] = train_df['clean_text'].apply(chop_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e46c6-56d6-4eca-80ce-d418ef304b6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f2f8bb-88c6-492a-bc0b-36afd74eacab",
   "metadata": {},
   "source": [
    "Lemmatization is a technique for reducing words to a normalized form. The transformation of lemmatization requires the use of a dictionary to map different versions of a word back to its root form. The `nltk` Library's `WordNetLemmatizer` will be used for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f486718-52c5-4e24-9df4-44c3ea925c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>[umgaqosiseko, wenza, amalungiselelo, kumaziko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>[idha, iya, kuba, nobulumko, bokubeka, umseben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>[province, kwazulunatal, department, transport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>[netefatša, gore, ba, file, dilo, ka, moka, tš...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>[khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  \\\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2     eng  the province of kwazulu-natal department of tr...   \n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [umgaqosiseko, wenza, amalungiselelo, kumaziko...  \n",
       "1  [idha, iya, kuba, nobulumko, bokubeka, umseben...  \n",
       "2  [province, kwazulunatal, department, transport...  \n",
       "3  [netefatša, gore, ba, file, dilo, ka, moka, tš...  \n",
       "4  [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize the text Messages:\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_df['clean_text'] = train_df['clean_text'].apply(lambda sentence: [lemmatizer.lemmatize(word) for word in sentence])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33885634-9ee9-4352-a632-e3e0ec9d369c",
   "metadata": {},
   "source": [
    "The Data Engineering phase has been completed, perhaps the new tokenized column should be reverted back to its normal state. This would show the new cleaner state of our data much more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "127957b1-5ba4-467a-9419-e138a164d59e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>umgaqosiseko wenza amalungiselelo kumaziko axh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>idha iya kuba nobulumko bokubeka umsebenzi nap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>province kwazulunatal department transport inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>netefatša gore ba file dilo ka moka tše le dum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  \\\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...   \n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...   \n",
       "2     eng  the province of kwazulu-natal department of tr...   \n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...   \n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  umgaqosiseko wenza amalungiselelo kumaziko axh...  \n",
       "1  idha iya kuba nobulumko bokubeka umsebenzi nap...  \n",
       "2  province kwazulunatal department transport inv...  \n",
       "3  netefatša gore ba file dilo ka moka tše le dum...  \n",
       "4  khomishini ya ndinganyiso ya mbeu yo ewa maana...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revert back to sentence:\n",
    "for i in range(len(train_df['clean_text'])):\n",
    "    train_df['clean_text'][i] = \" \".join(train_df['clean_text'][i])\n",
    "\n",
    "# Display Dataframe:\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f2ad99-f42b-4891-91d3-49d269b5ea49",
   "metadata": {},
   "source": [
    "#### Split Data Into Features and Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c69d084-3c26-4870-9c08-a945241739cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features and Labels:\n",
    "X = train_df['clean_text'] # Features\n",
    "y = train_df['lang_id'] # Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a61052-b2c8-4721-990b-0a4df6a21c46",
   "metadata": {},
   "source": [
    "#### Bag of Words:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233ada6-d1d9-4bad-9b21-b2eadf294c9e",
   "metadata": {},
   "source": [
    "There is a need for a way to represent text data for the Classification Machine Learning Algorithm. For this, the bag-of-words method helps with the task. It is a technique used to extract features from the text, for use in Machine Learning Algorithms. With this approach, the tokenized words for each observation are used to find out the frequency of each token. \n",
    "\n",
    "I have decided to use the `nltk` Library's `TfidfVectorizer` for this task because it often performs better at feature extraction than the `CountVectorizer`. I will begin by creating an instance of the vectorizer. The time has finally come to do some modeling. I will begin by splitting the DataFrame, thereafter extracting features (X) and properly defining the labels/target variable (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e3f8006-f029-4023-8378-ff8ffbd2d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vectorizer Instance:\n",
    "vect = TfidfVectorizer()                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc100b-3225-4d2e-bf81-b5a5e982490b",
   "metadata": {},
   "source": [
    "The next step is to use the `fit_transform()` to extract the features. This also extracts the vocabulary of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a47af99-97cf-4feb-b5b9-cf9cc970b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform extract features:\n",
    "X = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893664e2-164c-4022-9874-f77bc9a22af2",
   "metadata": {},
   "source": [
    "The Features and Labels will be split into a training set, for training the Classification Model and the validation set, for model validation. This will require the use of the `train_test_split()` function of Scikit-Learn (`sklearn`). The parameter of this function will be used to set the *random_state* as well as the *test_size*. The latter refers to how much of the data will be used for testing the trained model. For this task, the *test_size* parameter will be set to 20% (0.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa9acb99-7beb-48d8-8330-ac2daa39d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tain - Test Split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ada6a-863c-48ca-ad2a-33c190ca4dda",
   "metadata": {},
   "source": [
    "I will first create an instance of the **ComplementNB** Classifier, then proceed to train it using the **train set** defined in the previous step. The `.fit()` function will be used for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ComplementNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ComplementNB</label><div class=\"sk-toggleable__content\"><pre>ComplementNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Instance of Model:\n",
    "nb = ComplementNB()\n",
    "\n",
    "# Training the Naive Bayes Classifier using the training set:\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b723a67-61cb-4ea8-a4f2-354b211a3308",
   "metadata": {},
   "source": [
    "Now that the model has been trained, the next step is to validate it using the **validation set** defined earlier. This will require the use of the trained model to perform classification or to \"make predictions\" on the **validation set**, using `.predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e942e80-8fe9-4cc2-bf12-1c38e68e8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using trained model, on the test set:\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff02702-6fc7-43f2-a739-9a772df0a40b",
   "metadata": {},
   "source": [
    "##### Performance Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a70c15d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         xho       1.00      1.00      1.00       599\n",
      "         eng       0.99      1.00      1.00       632\n",
      "         nso       1.00      1.00      1.00       595\n",
      "         ven       1.00      1.00      1.00       582\n",
      "         tsn       1.00      1.00      1.00       610\n",
      "         nbl       1.00      1.00      1.00       607\n",
      "         zul       1.00      1.00      1.00       579\n",
      "         ssw       1.00      1.00      1.00       611\n",
      "         tso       1.00      1.00      1.00       605\n",
      "         sot       0.99      1.00      0.99       591\n",
      "         afr       1.00      0.98      0.99       589\n",
      "\n",
      "    accuracy                           1.00      6600\n",
      "   macro avg       1.00      1.00      1.00      6600\n",
      "weighted avg       1.00      1.00      1.00      6600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Naive Bayes Model:\n",
    "print(classification_report(y_test, y_pred, target_names=train_df['lang_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc8879-ddf2-4d93-9445-3bfe5a0290cb",
   "metadata": {},
   "source": [
    "As seen above, the trained `Complement Naive Bayes` performs exceptionally well on unseen data. This obviously makes it a great choice among classification models.\n",
    "I will now store the model. This ensures that it can be used at a later time, without the need to train a new model all over again. \n",
    "The `pickle` Library is well suited for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0740e-6e77-4510-8b83-02c06f003162",
   "metadata": {},
   "source": [
    "#### Storing the Trained Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c14c7766-b7f9-43ff-845f-3eccd5eefd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'NB_model.pkl' # Indicate the model's file name\n",
    "\n",
    "with open(save_path, 'wb') as file:\n",
    "    pickle.dump(nb, file) # Saving the model as a retrievable file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83590777-f0ea-4cb0-bd3c-d7701e3bf671",
   "metadata": {},
   "source": [
    "Now that the model is safely stored as a file, it can be retrieved and used for Classification tasks on new Datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b86482-90c4-45c1-a932-3277a9e9ea6f",
   "metadata": {},
   "source": [
    "#### Model Predictions on the Test Dataset:\n",
    "For the task of classification as with regression tasks, it is recommended that the original data preprocessing steps are repeated for the new dataset. The test dataset will be loaded and taken through the same preprocessing steps performed in the training dataset. This ensures that the data is presented to the trained model in the appropriate format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d39c38-0c13-4f2d-9693-2a417695f5ac",
   "metadata": {},
   "source": [
    "#### Load the Test Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "efa2bfd1-cf5d-4ea6-8f93-fe4ecdf7efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data as a Pandas DataFrame:\n",
    "test_df = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6897558-79dc-4078-9756-49bcb6fa61be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displying the DataFrame:\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35964e4e-e55e-47cc-abb3-276672b7ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuation:\n",
    "test_df['clean_text'] = test_df['text'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e5befc-22d2-4d7d-bebc-038d7fd8bae7",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9e04d445-cb4d-4e67-a3d0-c90c2a228247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "      <td>[Mmasepala, ,, fa, maemo, a, a, kgethegileng, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "      <td>[Uzakwaziswa, ngokufaneleko, nakungafuneka, em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "      <td>[Tshivhumbeo, tshi, fana, na, ngano, dza, vhat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "      <td>[Kube, inja, nelikati, betingevakala, kutsi, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "      <td>[Winste, op, buitelandse, valuta, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  \\\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...   \n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...   \n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.   \n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...   \n",
       "4      5                      Winste op buitelandse valuta.   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [Mmasepala, ,, fa, maemo, a, a, kgethegileng, ...  \n",
       "1  [Uzakwaziswa, ngokufaneleko, nakungafuneka, em...  \n",
       "2  [Tshivhumbeo, tshi, fana, na, ngano, dza, vhat...  \n",
       "3  [Kube, inja, nelikati, betingevakala, kutsi, t...  \n",
       "4               [Winste, op, buitelandse, valuta, .]  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting text into Tokens(word-lists):\n",
    "test_df['clean_text'] = test_df['text'].apply(tokenizer.tokenize)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bebe17-b961-422d-896e-d10e7770ab16",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1a6b9599-b391-450a-b6fa-eaa0e5ca2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['clean_text'] = test_df['clean_text'].apply(chop_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17073fde-5913-4da4-b6ac-4bef888ca819",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02df85f0-3dfe-404e-bb97-7d44a7aa9881",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "      <td>[Mmasepala, ,, fa, maemo, kgethegileng, letlel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "      <td>[Uzakwaziswa, ngokufaneleko, nakungafuneka, em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "      <td>[Tshivhumbeo, tshi, fana, na, ngano, dza, vhat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "      <td>[Kube, inja, nelikati, betingevakala, kutsi, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "      <td>[Winste, op, buitelandse, valuta, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  \\\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...   \n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...   \n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.   \n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...   \n",
       "4      5                      Winste op buitelandse valuta.   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [Mmasepala, ,, fa, maemo, kgethegileng, letlel...  \n",
       "1  [Uzakwaziswa, ngokufaneleko, nakungafuneka, em...  \n",
       "2  [Tshivhumbeo, tshi, fana, na, ngano, dza, vhat...  \n",
       "3  [Kube, inja, nelikati, betingevakala, kutsi, t...  \n",
       "4               [Winste, op, buitelandse, valuta, .]  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize the text Messages:\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "test_df['clean_text'] = test_df['clean_text'].apply(lambda sentence: [lemmatizer.lemmatize(word) for word in sentence])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0504f127-12a6-4351-8674-98978cb880f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "      <td>Mmasepala , fa maemo kgethegileng letlelela kg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "      <td>Winste op buitelandse valuta .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  \\\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...   \n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...   \n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.   \n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...   \n",
       "4      5                      Winste op buitelandse valuta.   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Mmasepala , fa maemo kgethegileng letlelela kg...  \n",
       "1  Uzakwaziswa ngokufaneleko nakungafuneka eminye...  \n",
       "2        Tshivhumbeo tshi fana na ngano dza vhathu .  \n",
       "3  Kube inja nelikati betingevakala kutsi titsini...  \n",
       "4                     Winste op buitelandse valuta .  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revert back to sentence:\n",
    "for i in range(len(test_df['clean_text'])):\n",
    "    test_df['clean_text'][i] = \" \".join(test_df['clean_text'][i])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b2d10f-b335-4ebd-99a8-240ee78b1d65",
   "metadata": {},
   "source": [
    "Looking at the first row of the **clean_test** column, it appears that some punctuation characters slipped through. There is a need to call the `remove_punctuation()` function again, just to be thorough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b1a861f-777e-4a6e-8918-9d5522cad1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "      <td>Mmasepala  fa maemo kgethegileng letlelela kga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "      <td>Winste op buitelandse valuta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  \\\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...   \n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...   \n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.   \n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...   \n",
       "4      5                      Winste op buitelandse valuta.   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Mmasepala  fa maemo kgethegileng letlelela kga...  \n",
       "1  Uzakwaziswa ngokufaneleko nakungafuneka eminye...  \n",
       "2         Tshivhumbeo tshi fana na ngano dza vhathu   \n",
       "3  Kube inja nelikati betingevakala kutsi titsini...  \n",
       "4                      Winste op buitelandse valuta   "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['clean_text'] = test_df['clean_text'].apply(remove_punctuation)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd40cab-1cfd-4e5e-9490-0664c28ef022",
   "metadata": {},
   "source": [
    "#### Load Saved Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d82ad3d3-d772-4034-8f38-31fb2708882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'NB_model.pkl'\n",
    "with open(model_path, 'rb') as file:\n",
    "    unpickled_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d38c16-8dce-4c4d-b76e-242c5516fa6c",
   "metadata": {},
   "source": [
    "Just like before, the feature column must be well defined, before the process of feature extraction.\n",
    "This time, there is no need to fit the `Tfidfvectorizer` to the data again, because the 'vocabulary' has already been learned.\n",
    "What needs to happen now is purely feature extraction, and for this, the `.transform()` method will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ad236ba6-7e51-4059-a1ab-95acf37d5438",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = test_df['clean_text'] # Features\n",
    "X1 = vect.transform(X1) # Extract features from the data using Tfidfvectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9cbeb-9add-4aa8-870f-ef325dd6b4c1",
   "metadata": {},
   "source": [
    "Classification tasks are all about determining the **probability** of an observation belonging to a particular class (discreet values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac508f66-82c3-4150-9314-1525eb4fe44e",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d1247878-690f-4748-b2a0-c1458c82d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = unpickled_model.predict(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28028ab8-9cf5-419a-855b-c3fdf6291140",
   "metadata": {},
   "source": [
    "The task has been performed successfully. For the purpose of making Kaggle submissions, the results will be stored in the form of a `pandas` DataFrame and saved as a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9186515-e40b-468c-a8a9-f7c4370172c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame for the Results:\n",
    "preds = pd.DataFrame()\n",
    "preds['index'] = test_df.index + 1\n",
    "preds['lang_id'] = y_hat\n",
    "preds.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c3c36c63-86db-4343-a812-cae2be760247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction as .csv:\n",
    "preds.to_csv('nb_preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc16c0c-4d3a-49ec-89d4-406d9f052e34",
   "metadata": {},
   "source": [
    "Finally, I will have a look at the new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "08c3d313-2104-4e8e-b9a6-7bbb26788b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>afr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lang_id\n",
       "index        \n",
       "1         tsn\n",
       "2         nbl\n",
       "3         ven\n",
       "4         ssw\n",
       "5         afr"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanation\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "I will choose Naive Bayes Classifier. \n",
    "It is a probabilistic Machine Learning Model that is based on the **Bayes theorem**.\n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
